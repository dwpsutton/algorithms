{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 QuickSort\
\

\b0 \ulnone Hoare 1961.  Uses randomization to produce an average run time of O(nlogn), but with small runtime constants and low memory usage (as operations can be done in place).\
\
In 
\b summary
\b0 , the method chooses a pivot i and partitions the array on the pivot, such that any element with A[j] < A[i] ends up on the left of A[i], and any with A[j] > A[i] ends up on the right.  A recursive QuickSort is the called on each of the two partitions.  The partition operation is O(n), as the pivot must be compared to every element in the array.\
\
The 
\b partition algorithm
\b0  can run in place.  We keep track of two indices, the index of the largest element i smaller than the pivot l, A[i] < A[l], and the largest index that we have compared on so far, j.  If A[j+1] < A[l], we swap A[i+1] and A[j+1] and increment i and j.  Otherwise we only increment j.  So the swap occurs in place and only occurs when A[j] is greater than the pivot A[l].  This means the work per recursion is dominated by the comparison operation.\
\
The choice of 
\b pivot
\b0  is extremely important.  In the worse case scenario, we have a sorted list and always choose the left most element for partition.  Then we recurse on an array of length n-1, so recursion tree has n levels, making the algorithm O(n^2).  In the best case, we always choose the median of the unsorted sub arrays, resulting in an O(nlogn) runtime.  The pivot choice is important to get closer to best case rather than worst case.\
\
If we 
\b randomise
\b0  the pivot choice, we can prove that the expected runtime <T(n)> = O(nlogn).  See below for proof.\
\

\b \ul Proof of <T(n)> = O(nlogn)\
\

\b0 \ulnone We saw above that the number of operations per recursion is O(C), where C is the number of comparisons.  The overall work, then, is the total number of comparisons summed over all recursions.\
\
If we index elements by their eventual ordering (still unknown), we can see that A[i] and A[j], where i< j, can only be compared 
\b once or not at all during all recursions
\b0 .  If the pivot was at element k, where i<k<j, then i and j will never have been compared.  
\b They will only be compared if the pivot is i or j, not if the pivot is between i and j.\

\b0 \
We can therefore write that the number of comparisons, X_ij = 1, 0 (an indicator function),  \
\
Summing over all recursions, the total comparisons were:\
\
C(s)= sum_(i=1)^(i=n-1) sum_(j=i+1)^(j=n) X_ij(s)\
\
where \'92s\'92 is the set of chosen pivots.\
\
If we randomise the pivot choice s, and following the reasoning above that comparisons only occur if the pivot was i or j, not between i and j, then the expected number of comparisons is \
\
<X_ij> = 2 / ( j-i+1 )\
\
The expectation of a sum is the sum of expectations, so:\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 <C(s)>= sum_(i=1)^(i=n-1) sum_(j=i+1)^(j=n) <X_ij(s)>\
	   = sum_(i=1)^(i=n-1) sum_(j=i+1)^(j=n) 2/ (j-i+1)\
	 <= 2n sum_(k=2)^(k=n) 1/k\
\
If we integrate this sum over k, (as we have an inequality, we can swap out lower limit of 2 for a limit of 1 to get log(1)=0) we end up with:\
\
<C(s)>   <=  2n log n\
\
QED}